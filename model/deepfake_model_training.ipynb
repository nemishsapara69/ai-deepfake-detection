{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a6fa60",
   "metadata": {},
   "source": [
    "# Deepfake Detection Model Training\n",
    "This notebook trains a deep learning model to classify real vs fake (AI-generated) faces using Transfer Learning with EfficientNetB4.\n",
    "\n",
    "## Model Architecture:\n",
    "- **Base Model**: EfficientNetB4 (pre-trained on ImageNet)\n",
    "- **Custom Head**: Global Average Pooling â†’ Dense Layers â†’ Dropout â†’ Sigmoid Output\n",
    "- **Loss Function**: Binary Crossentropy\n",
    "- **Optimizer**: Adam with learning rate scheduling\n",
    "\n",
    "## Dataset Structure:\n",
    "```\n",
    "dataset/\n",
    "â”œâ”€â”€ train/\n",
    "â”‚   â”œâ”€â”€ real/\n",
    "â”‚   â””â”€â”€ fake/\n",
    "â””â”€â”€ validation/\n",
    "    â”œâ”€â”€ real/\n",
    "    â””â”€â”€ fake/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ba550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB4, ResNet50, Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Hyperparameters\n",
    "IMG_SIZE = 224  # EfficientNetB4 input size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "FINE_TUNE_EPOCHS = 20\n",
    "FINE_TUNE_AT = 100  # Layer to start fine-tuning from\n",
    "\n",
    "# Paths\n",
    "TRAIN_DIR = '../dataset/train'\n",
    "VAL_DIR = '../dataset/validation'\n",
    "MODEL_SAVE_PATH = './saved_models/deepfake_detector_efficientnet.h5'\n",
    "WEIGHTS_SAVE_PATH = './saved_models/deepfake_detector_weights.h5'\n",
    "\n",
    "# Create model directory\n",
    "os.makedirs('./saved_models', exist_ok=True)\n",
    "os.makedirs('./logs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Only rescaling for validation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nClass Indices: {train_generator.class_indices}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f659b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def plot_sample_images(generator, num_images=8):\n",
    "    \"\"\"Plot sample images from the dataset\"\"\"\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Get a batch of images\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    for i in range(min(num_images, len(images))):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        label = 'FAKE' if labels[i] == 0 else 'REAL'\n",
    "        color = 'red' if labels[i] == 0 else 'green'\n",
    "        plt.title(f'Label: {label}', color=color, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model using Transfer Learning\n",
    "def create_model(base_model_name='EfficientNetB4'):\n",
    "    \"\"\"Create deepfake detection model with transfer learning\"\"\"\n",
    "    \n",
    "    # Load pre-trained base model\n",
    "    if base_model_name == 'EfficientNetB4':\n",
    "        base_model = EfficientNetB4(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "        )\n",
    "    elif base_model_name == 'ResNet50':\n",
    "        base_model = ResNet50(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "        )\n",
    "    elif base_model_name == 'Xception':\n",
    "        base_model = Xception(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "        )\n",
    "    \n",
    "    # Freeze base model layers initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build the model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create the model\n",
    "model, base_model = create_model('EfficientNetB4')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_SAVE_PATH,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='./logs',\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stop, reduce_lr, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20bdbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model (Initial Training with Frozen Base)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Initial Training (Frozen Base Model)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tuning: Unfreeze some layers of the base model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Fine-Tuning\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze layers before FINE_TUNE_AT\n",
    "for layer in base_model.layers[:FINE_TUNE_AT]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE / 10),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Continue training\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS + FINE_TUNE_EPOCHS,\n",
    "    initial_epoch=len(history.history['loss']),\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "def plot_training_history(history, history_fine=None):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    \n",
    "    # Combine histories if fine-tuning was done\n",
    "    if history_fine:\n",
    "        acc = history.history['accuracy'] + history_fine.history['accuracy']\n",
    "        val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']\n",
    "        loss = history.history['loss'] + history_fine.history['loss']\n",
    "        val_loss = history.history['val_loss'] + history_fine.history['val_loss']\n",
    "    else:\n",
    "        acc = history.history['accuracy']\n",
    "        val_acc = history.history['val_accuracy']\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs_range = range(len(acc))\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy', linewidth=2)\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss', linewidth=2)\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./logs/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history, history_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5874c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Evaluation on Validation Set\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Load best model\n",
    "best_model = keras.models.load_model(MODEL_SAVE_PATH)\n",
    "\n",
    "# Evaluate\n",
    "results = best_model.evaluate(val_generator, verbose=1)\n",
    "print(f\"\\nValidation Loss: {results[0]:.4f}\")\n",
    "print(f\"Validation Accuracy: {results[1]:.4f}\")\n",
    "print(f\"Validation Precision: {results[2]:.4f}\")\n",
    "print(f\"Validation Recall: {results[3]:.4f}\")\n",
    "print(f\"Validation AUC: {results[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ef4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions and Confusion Matrix\n",
    "# Reset generator\n",
    "val_generator.reset()\n",
    "\n",
    "# Get predictions\n",
    "predictions = best_model.predict(val_generator, verbose=1)\n",
    "y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=['FAKE', 'REAL']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['FAKE', 'REAL'], yticklabels=['FAKE', 'REAL'])\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.savefig('./logs/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fdb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('./logs/roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model in Different Formats\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Saving Model\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Save as .h5\n",
    "best_model.save(MODEL_SAVE_PATH)\n",
    "print(f\"âœ… Model saved as: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "# Save weights only\n",
    "best_model.save_weights(WEIGHTS_SAVE_PATH)\n",
    "print(f\"âœ… Weights saved as: {WEIGHTS_SAVE_PATH}\")\n",
    "\n",
    "# Save in TensorFlow SavedModel format (for production)\n",
    "tf_save_path = './saved_models/deepfake_detector_savedmodel'\n",
    "best_model.save(tf_save_path, save_format='tf')\n",
    "print(f\"âœ… TensorFlow SavedModel saved at: {tf_save_path}\")\n",
    "\n",
    "# Save model architecture as JSON\n",
    "model_json = best_model.to_json()\n",
    "with open('./saved_models/model_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(f\"âœ… Model architecture saved as JSON\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Model training completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Function\n",
    "def predict_image(image_path, model):\n",
    "    \"\"\"Predict if an image is real or fake\"\"\"\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "    \n",
    "    # Interpret result\n",
    "    if prediction < 0.5:\n",
    "        result = \"FAKE\"\n",
    "        confidence = (1 - prediction) * 100\n",
    "    else:\n",
    "        result = \"REAL\"\n",
    "        confidence = prediction * 100\n",
    "    \n",
    "    return result, confidence, prediction\n",
    "\n",
    "# Example usage (uncomment and provide test image path)\n",
    "# test_image_path = '../test_images/sample.jpg'\n",
    "# result, confidence, score = predict_image(test_image_path, best_model)\n",
    "# print(f\"Result: {result}\")\n",
    "# print(f\"Confidence: {confidence:.2f}%\")\n",
    "# print(f\"Raw Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac3725",
   "metadata": {},
   "source": [
    "## Model Training Complete! ðŸŽ‰\n",
    "\n",
    "### Next Steps:\n",
    "1. Test the model with sample images\n",
    "2. Integrate with Flask/FastAPI backend\n",
    "3. Deploy to production\n",
    "\n",
    "### Model Files Generated:\n",
    "- `deepfake_detector_efficientnet.h5` - Complete model\n",
    "- `deepfake_detector_weights.h5` - Model weights only\n",
    "- `deepfake_detector_savedmodel/` - TensorFlow SavedModel format\n",
    "- `model_architecture.json` - Model architecture\n",
    "\n",
    "### Performance Metrics:\n",
    "Check the logs folder for:\n",
    "- Training history plots\n",
    "- Confusion matrix\n",
    "- ROC curve\n",
    "- TensorBoard logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5068917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd435d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Using Pretrained Model from Kaggle\n",
    "# If you don't have time to train, download a pretrained model\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Option 1: Download from Kaggle (Real and Fake Face Detection dataset)\n",
    "# Dataset: https://www.kaggle.com/datasets/ciplab/real-and-fake-face-detection\n",
    "# This dataset contains real and fake face images perfect for deepfake detection\n",
    "\n",
    "def download_pretrained_model_from_kaggle():\n",
    "    \"\"\"\n",
    "    Instructions for downloading and using pretrained model from Kaggle\n",
    "    \"\"\"\n",
    "    print(\"To use a pretrained model instead of training:\")\n",
    "    print(\"1. Go to: https://www.kaggle.com/datasets/ciplab/real-and-fake-face-detection\")\n",
    "    print(\"2. Download the dataset (contains real and fake face images)\")\n",
    "    print(\"3. Extract to '../dataset/' folder\")\n",
    "    print(\"4. Use the dataset structure:\")\n",
    "    print(\"   dataset/\")\n",
    "    print(\"   â”œâ”€â”€ train/\")\n",
    "    print(\"   â”‚   â”œâ”€â”€ real/\")\n",
    "    print(\"   â”‚   â””â”€â”€ fake/\")\n",
    "    print(\"   â””â”€â”€ validation/\")\n",
    "    print(\"       â”œâ”€â”€ real/\")\n",
    "    print(\"       â””â”€â”€ fake/\")\n",
    "    print()\n",
    "    print(\"5. If you find a pretrained model (.h5 file) on Kaggle,\")\n",
    "    print(\"   download it and use the code below to load it:\")\n",
    "\n",
    "    # Example code to load pretrained model\n",
    "    pretrained_model_path = \"./pretrained_models/deepfake_detector.h5\"\n",
    "\n",
    "    if os.path.exists(pretrained_model_path):\n",
    "        try:\n",
    "            model = keras.models.load_model(pretrained_model_path)\n",
    "            print(f\"âœ… Pretrained model loaded from {pretrained_model_path}\")\n",
    "\n",
    "            # Test the model\n",
    "            print(\"Model summary:\")\n",
    "            model.summary()\n",
    "\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading pretrained model: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"âŒ Pretrained model not found at {pretrained_model_path}\")\n",
    "        print(\"Please download a pretrained model from Kaggle and place it there.\")\n",
    "        return None\n",
    "\n",
    "# Uncomment to try loading pretrained model\n",
    "# pretrained_model = download_pretrained_model_from_kaggle()\n",
    "\n",
    "# If you have a pretrained model, you can skip training and go directly to evaluation\n",
    "# Just replace 'model' with 'pretrained_model' in the evaluation cells above\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRETRAINED MODEL INSTRUCTIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"If you want to skip training entirely:\")\n",
    "print(\"1. Find a deepfake detection model on Kaggle\")\n",
    "print(\"2. Download the .h5 model file\")\n",
    "print(\"3. Place it in './pretrained_models/' folder\")\n",
    "print(\"4. Uncomment and run the download_pretrained_model_from_kaggle() function\")\n",
    "print(\"5. Use the loaded model for inference instead of training\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
